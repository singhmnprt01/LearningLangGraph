{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa598844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "import math\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e06ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskManagerState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    \n",
    "    tasks: list[dict]\n",
    "    \n",
    "    # task_history: list[str]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436d1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f6f2197",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add_task(title: str, priority: str ='medium') -> str:\n",
    "    \"\"\" add a new task to the list\"\"\"\n",
    "    global counter\n",
    "    counter += 1\n",
    "    print(f\"Task {title} added with priority {priority}\")\n",
    "    return {'id': counter,\n",
    "            'title':title,\n",
    "            'priority':priority,\n",
    "            'status':'pending'}\n",
    " \n",
    "\n",
    "@tool\n",
    "def remove_task(task_id: int) -> str:\n",
    "    \"\"\" deletes the task based on the task_id\"\"\"\n",
    "    print(f\"Task {task_id} removed successfully\")\n",
    "    return {'id':task_id}\n",
    "\n",
    "\n",
    "@tool\n",
    "def update_task(task_id: int, title: str = None, priority: str = None) -> str:\n",
    "    \"\"\"Update task title or priority\"\"\"\n",
    "    print(f\"Task {task_id} updated successfully\")\n",
    "    return {\"id\": task_id, \"title\": title, \"priority\": priority}\n",
    "\n",
    "\n",
    "tools = [add_task, remove_task,update_task]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de8c9551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Language model initialized with tools\n",
      "  Model: gpt-4.1-mini\n",
      "  Available tools: 3\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Method 4: Pass api_key directly to ChatOpenAI (not recommended)\n",
    "# llm = ChatOpenAI(model=\"gpt-4\", temperature=0, api_key=\"your-api-key-here\")\n",
    "model_name= \"gpt-4.1-mini\"\n",
    "# Create the base LLM (temperature=0 for deterministic responses)\n",
    "llm = ChatOpenAI(model=model_name, temperature=0)\n",
    "\n",
    "# Bind the calculation tools to the LLM\n",
    "# This enables the model to call these tools when needed\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"✓ Language model initialized with tools\")\n",
    "print(f\"  Model: {model_name}\")\n",
    "print(f\"  Available tools: {len(tools)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0802f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: TaskManagerState) -> dict:\n",
    "    \"\"\"\n",
    "    This node calls the LLM with the current conversation history.\n",
    "    The LLM will either:\n",
    "    - Call one or more tools (for calculations)\n",
    "    - Respond with a final answer (no more tools needed)\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    print(f\"\"\"Step1: Run the call_model function with message as {state[\"messages\"]}\"\"\")\n",
    "    \n",
    "    # Invoke the LLM with tools\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    print(f\"Response from 'llm_with_tools.invoke(messages)' command is {response}\\n\")\n",
    "    # Return the response as a new message to be added to state\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def call_tools(state: TaskManagerState) -> dict:\n",
    "    \"\"\"This node executes all tool calls from the last agent message.\n",
    "        It runs the actual task tools and returns the results.\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    last_messages = messages[-1]\n",
    "    \n",
    "    tool_calls = last_messages.tool_calls\n",
    "    \n",
    "    tool_map = {tool.name:tool for tool in tools}\n",
    "    \n",
    "    tool_messages=[]\n",
    "    tasks = state.get('tasks',[])\n",
    "    \n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "        tool_id = tool_call[\"id\"]\n",
    "    \n",
    "        selected_tool = tool_map[tool_name]\n",
    "    \n",
    "        try:\n",
    "            result = selected_tool.invoke(tool_args)\n",
    "        #    task_record = f\"{tool_name}({', '.join(map(str, tool_args.values()))}) = {result}\"\n",
    "            if tool_name=='add_task':\n",
    "               tasks.append(result)\n",
    "               \n",
    "            if tool_name=='remove_task' and len(tasks)>0:\n",
    "               tasks = [task for task in tasks if task.get('id') != result['id']]\n",
    "            \n",
    "            if tool_name == 'update_task' and len(tasks)>0:\n",
    "                task_to_be_updated = [task for task in tasks if task.get('id')==result['id']]\n",
    "                matching_task = task_to_be_updated[0]\n",
    "                if matching_task['title'] is not None:\n",
    "                    matching_task['title'] = result['title']\n",
    "                if matching_task['priority'] is not None:\n",
    "                    matching_task['priority'] = result['priority']\n",
    "                \n",
    "                tasks = [task if task.get('id') != result['id'] else matching_task for task in tasks]\n",
    "                \n",
    "                # remaining_tasks = [task for task in tasks if task.get('id')!=result['id']]\n",
    "                # task_to_be_updated['title']=result['title']\n",
    "                # task_to_be_updated['priority']=result['priority']\n",
    "                # remaining_tasks.append(task_to_be_updated)\n",
    "                # tasks = remaining_tasks\n",
    "                # # {\"id\": task_id, \"title\": title, \"priority\": priority}\n",
    "                \n",
    "            tool_messages.append(\n",
    "               ToolMessage(\n",
    "                   content=str(result),\n",
    "                   tool_call_id = tool_id,\n",
    "                   name=tool_name))\n",
    "           \n",
    "        except Exception as e:\n",
    "            # Handle any errors during tool execution\n",
    "               tool_messages.append(\n",
    "                ToolMessage(\n",
    "                content=f\"Error: {str(e)}\",\n",
    "                tool_call_id=tool_id,\n",
    "                name=tool_name\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return {\n",
    "        \"messages\": tool_messages,\n",
    "        \"tasks\": tasks\n",
    "    }\n",
    "    \n",
    "    \n",
    "def should_continue(state: TaskManagerState) -> str:\n",
    "    \"\"\"\n",
    "    This function checks if the agent wants to use more tools.\n",
    "    If there are tool calls in the last message, we continue to the tools node.\n",
    "    Otherwise, we end the execution.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Now, we have entered into should_continue function. After call_model and before should_contninue, langGraph appends the state['mesage']  based the state['message] + response from lllm_with_tools.invoke(messages)\")\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # Check if there are any tool calls in the last message\n",
    "    if not hasattr(last_message, \"tool_calls\") or not last_message.tool_calls:\n",
    "        print(\"Step2: Run the should_continue function -- END\")\n",
    "        print(f\"In should_continue, message from state['message] is {messages}\\n\")\n",
    "        return \"end\"  # No more tools to call, we're done\n",
    "    \n",
    "    print(\"Step2: Run the should_continue function -- CONTINUE\")\n",
    "    print(f\"In should_continue, message from state['message] is {messages}\\n\")\n",
    "    \n",
    "    return \"continue\"  # More tools to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "873a3dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Calculator graph created and compiled!\n",
      "\n",
      "Graph structure:\n",
      "  START → agent → [conditional] → tools → agent → ... → END\n"
     ]
    }
   ],
   "source": [
    "# Function to create and compile the task manager graph\n",
    "def create_taskmanager_graph():\n",
    "    \"\"\"\n",
    "    Build the LangGraph calculator agent.\n",
    "    Returns a compiled graph ready for execution.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the StateGraph with our state schema\n",
    "    workflow = StateGraph(TaskManagerState)\n",
    "    \n",
    "    # Add nodes to the graph\n",
    "    # \"agent\" node: calls the LLM to make decisions\n",
    "    workflow.add_node(\"TaskAgent\", call_model)\n",
    "    \n",
    "    # \"tools\" node: executes the calculation tools\n",
    "    workflow.add_node(\"TaskTools\", call_tools)\n",
    "    \n",
    "    # Set the entry point (where execution starts)\n",
    "    workflow.set_entry_point(\"TaskAgent\")\n",
    "    \n",
    "    # Add conditional edges from agent node\n",
    "    # Based on should_continue(), either go to tools or END\n",
    "    workflow.add_conditional_edges(\n",
    "        \"TaskAgent\",  # From the agent node\n",
    "        should_continue,  # Use this function to decide\n",
    "        {\n",
    "            \"continue\": \"TaskTools\",  # If continue, go to tools node\n",
    "            \"end\": END  # If end, finish execution\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Add edge from tools back to agent\n",
    "    # This creates the loop: agent → tools → agent → ...\n",
    "    workflow.add_edge(\"TaskTools\", \"TaskAgent\")\n",
    "    \n",
    "    # Compile the graph into an executable form\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "# Create the calculator graph\n",
    "taskmanager_graph = create_taskmanager_graph()\n",
    "\n",
    "print(\"✓ Calculator graph created and compiled!\")\n",
    "print(\"\\nGraph structure:\")\n",
    "print(\"  START → agent → [conditional] → tools → agent → ... → END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0c33052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000024028A975E0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taskmanager_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e84b023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Helper function ready to use\n"
     ]
    }
   ],
   "source": [
    "# Helper function to run the calculator agent with a question\n",
    "def run_calculator_agent(question: str, verbose: bool = True):\n",
    "    \"\"\"\n",
    "    Run the calculator agent with a user question.\n",
    "    \n",
    "    Args:\n",
    "        question: The user's calculation question in natural language\n",
    "        verbose: If True, print detailed output\n",
    "    \n",
    "    Returns:\n",
    "        The final state containing all messages and calculation history\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the state with the user's question\n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=question)],\n",
    "        \"tasks\": []\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Invoke the graph with the initial state\n",
    "    # The graph will run until it reaches END\n",
    "    result = taskmanager_graph.invoke(initial_state)\n",
    "    \n",
    "    if verbose:\n",
    "        # Display all calculation steps\n",
    "        if result.get(\"tasks\"):\n",
    "            print(\"tasks Steps:\")\n",
    "            for i, calc in enumerate(result[\"tasks\"], 1):\n",
    "                print(f\"   {i}. {calc}\")\n",
    "            print()\n",
    "        \n",
    "        # Display the final answer from the agent\n",
    "        final_message = result[\"messages\"][-1]\n",
    "        print(f\"Final Answer: {final_message.content}\\n\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"✓ Helper function ready to use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c6f5537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Question: add task to bring milk as high priority, then add task to clean the house as medium priority. \n",
      "                                Now, delete task 1 and update priority of task 2 to very high\n",
      "======================================================================\n",
      "\n",
      "Step1: Run the call_model function with message as [HumanMessage(content='add task to bring milk as high priority, then add task to clean the house as medium priority. \\n                                Now, delete task 1 and update priority of task 2 to very high', additional_kwargs={}, response_metadata={})]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from 'llm_with_tools.invoke(messages)' command is content='' additional_kwargs={'tool_calls': [{'id': 'call_PA3Ro2oFSfeK4c5QvxDHPQDs', 'function': {'arguments': '{\"title\": \"bring milk\", \"priority\": \"high\"}', 'name': 'add_task'}, 'type': 'function'}, {'id': 'call_lcWOqF5LVUUk4igldM4wRhYM', 'function': {'arguments': '{\"title\": \"clean the house\", \"priority\": \"medium\"}', 'name': 'add_task'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 162, 'total_tokens': 217, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--ce4f24f9-b563-454e-b7a7-4f04b263f23b-0' tool_calls=[{'name': 'add_task', 'args': {'title': 'bring milk', 'priority': 'high'}, 'id': 'call_PA3Ro2oFSfeK4c5QvxDHPQDs', 'type': 'tool_call'}, {'name': 'add_task', 'args': {'title': 'clean the house', 'priority': 'medium'}, 'id': 'call_lcWOqF5LVUUk4igldM4wRhYM', 'type': 'tool_call'}] usage_metadata={'input_tokens': 162, 'output_tokens': 55, 'total_tokens': 217, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "Now, we have entered into should_continue function. After call_model and before should_contninue, langGraph appends the state['mesage']  based the state['message] + response from lllm_with_tools.invoke(messages)\n",
      "Step2: Run the should_continue function -- CONTINUE\n",
      "In should_continue, message from state['message] is [HumanMessage(content='add task to bring milk as high priority, then add task to clean the house as medium priority. \\n                                Now, delete task 1 and update priority of task 2 to very high', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_PA3Ro2oFSfeK4c5QvxDHPQDs', 'function': {'arguments': '{\"title\": \"bring milk\", \"priority\": \"high\"}', 'name': 'add_task'}, 'type': 'function'}, {'id': 'call_lcWOqF5LVUUk4igldM4wRhYM', 'function': {'arguments': '{\"title\": \"clean the house\", \"priority\": \"medium\"}', 'name': 'add_task'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 162, 'total_tokens': 217, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ce4f24f9-b563-454e-b7a7-4f04b263f23b-0', tool_calls=[{'name': 'add_task', 'args': {'title': 'bring milk', 'priority': 'high'}, 'id': 'call_PA3Ro2oFSfeK4c5QvxDHPQDs', 'type': 'tool_call'}, {'name': 'add_task', 'args': {'title': 'clean the house', 'priority': 'medium'}, 'id': 'call_lcWOqF5LVUUk4igldM4wRhYM', 'type': 'tool_call'}], usage_metadata={'input_tokens': 162, 'output_tokens': 55, 'total_tokens': 217, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "Task bring milk added with priority high\n",
      "Task clean the house added with priority medium\n",
      "Step1: Run the call_model function with message as [HumanMessage(content='add task to bring milk as high priority, then add task to clean the house as medium priority. \\n                                Now, delete task 1 and update priority of task 2 to very high', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_PA3Ro2oFSfeK4c5QvxDHPQDs', 'function': {'arguments': '{\"title\": \"bring milk\", \"priority\": \"high\"}', 'name': 'add_task'}, 'type': 'function'}, {'id': 'call_lcWOqF5LVUUk4igldM4wRhYM', 'function': {'arguments': '{\"title\": \"clean the house\", \"priority\": \"medium\"}', 'name': 'add_task'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 162, 'total_tokens': 217, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ce4f24f9-b563-454e-b7a7-4f04b263f23b-0', tool_calls=[{'name': 'add_task', 'args': {'title': 'bring milk', 'priority': 'high'}, 'id': 'call_PA3Ro2oFSfeK4c5QvxDHPQDs', 'type': 'tool_call'}, {'name': 'add_task', 'args': {'title': 'clean the house', 'priority': 'medium'}, 'id': 'call_lcWOqF5LVUUk4igldM4wRhYM', 'type': 'tool_call'}], usage_metadata={'input_tokens': 162, 'output_tokens': 55, 'total_tokens': 217, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"{'id': 1, 'title': 'bring milk', 'priority': 'high', 'status': 'pending'}\", name='add_task', tool_call_id='call_PA3Ro2oFSfeK4c5QvxDHPQDs'), ToolMessage(content=\"{'id': 2, 'title': 'clean the house', 'priority': 'medium', 'status': 'pending'}\", name='add_task', tool_call_id='call_lcWOqF5LVUUk4igldM4wRhYM')]\n",
      "Response from 'llm_with_tools.invoke(messages)' command is content='' additional_kwargs={'tool_calls': [{'id': 'call_k2qrU2eFWHnizJDbv0gErQhB', 'function': {'arguments': '{\"task_id\": 1}', 'name': 'remove_task'}, 'type': 'function'}, {'id': 'call_jsSobx5FHggl1KxqnYJ61QNQ', 'function': {'arguments': '{\"task_id\": 2, \"priority\": \"very high\"}', 'name': 'update_task'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 282, 'total_tokens': 333, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--12088140-aa72-43f9-bd82-354d5a44f1fc-0' tool_calls=[{'name': 'remove_task', 'args': {'task_id': 1}, 'id': 'call_k2qrU2eFWHnizJDbv0gErQhB', 'type': 'tool_call'}, {'name': 'update_task', 'args': {'task_id': 2, 'priority': 'very high'}, 'id': 'call_jsSobx5FHggl1KxqnYJ61QNQ', 'type': 'tool_call'}] usage_metadata={'input_tokens': 282, 'output_tokens': 51, 'total_tokens': 333, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "Now, we have entered into should_continue function. After call_model and before should_contninue, langGraph appends the state['mesage']  based the state['message] + response from lllm_with_tools.invoke(messages)\n",
      "Step2: Run the should_continue function -- CONTINUE\n",
      "In should_continue, message from state['message] is [HumanMessage(content='add task to bring milk as high priority, then add task to clean the house as medium priority. \\n                                Now, delete task 1 and update priority of task 2 to very high', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_PA3Ro2oFSfeK4c5QvxDHPQDs', 'function': {'arguments': '{\"title\": \"bring milk\", \"priority\": \"high\"}', 'name': 'add_task'}, 'type': 'function'}, {'id': 'call_lcWOqF5LVUUk4igldM4wRhYM', 'function': {'arguments': '{\"title\": \"clean the house\", \"priority\": \"medium\"}', 'name': 'add_task'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 162, 'total_tokens': 217, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ce4f24f9-b563-454e-b7a7-4f04b263f23b-0', tool_calls=[{'name': 'add_task', 'args': {'title': 'bring milk', 'priority': 'high'}, 'id': 'call_PA3Ro2oFSfeK4c5QvxDHPQDs', 'type': 'tool_call'}, {'name': 'add_task', 'args': {'title': 'clean the house', 'priority': 'medium'}, 'id': 'call_lcWOqF5LVUUk4igldM4wRhYM', 'type': 'tool_call'}], usage_metadata={'input_tokens': 162, 'output_tokens': 55, 'total_tokens': 217, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"{'id': 1, 'title': 'bring milk', 'priority': 'high', 'status': 'pending'}\", name='add_task', tool_call_id='call_PA3Ro2oFSfeK4c5QvxDHPQDs'), ToolMessage(content=\"{'id': 2, 'title': 'clean the house', 'priority': 'medium', 'status': 'pending'}\", name='add_task', tool_call_id='call_lcWOqF5LVUUk4igldM4wRhYM'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_k2qrU2eFWHnizJDbv0gErQhB', 'function': {'arguments': '{\"task_id\": 1}', 'name': 'remove_task'}, 'type': 'function'}, {'id': 'call_jsSobx5FHggl1KxqnYJ61QNQ', 'function': {'arguments': '{\"task_id\": 2, \"priority\": \"very high\"}', 'name': 'update_task'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 282, 'total_tokens': 333, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--12088140-aa72-43f9-bd82-354d5a44f1fc-0', tool_calls=[{'name': 'remove_task', 'args': {'task_id': 1}, 'id': 'call_k2qrU2eFWHnizJDbv0gErQhB', 'type': 'tool_call'}, {'name': 'update_task', 'args': {'task_id': 2, 'priority': 'very high'}, 'id': 'call_jsSobx5FHggl1KxqnYJ61QNQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 282, 'output_tokens': 51, 'total_tokens': 333, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "Task 1 removed successfully\n",
      "Task 2 updated successfully\n",
      "Step1: Run the call_model function with message as [HumanMessage(content='add task to bring milk as high priority, then add task to clean the house as medium priority. \\n                                Now, delete task 1 and update priority of task 2 to very high', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_PA3Ro2oFSfeK4c5QvxDHPQDs', 'function': {'arguments': '{\"title\": \"bring milk\", \"priority\": \"high\"}', 'name': 'add_task'}, 'type': 'function'}, {'id': 'call_lcWOqF5LVUUk4igldM4wRhYM', 'function': {'arguments': '{\"title\": \"clean the house\", \"priority\": \"medium\"}', 'name': 'add_task'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 162, 'total_tokens': 217, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ce4f24f9-b563-454e-b7a7-4f04b263f23b-0', tool_calls=[{'name': 'add_task', 'args': {'title': 'bring milk', 'priority': 'high'}, 'id': 'call_PA3Ro2oFSfeK4c5QvxDHPQDs', 'type': 'tool_call'}, {'name': 'add_task', 'args': {'title': 'clean the house', 'priority': 'medium'}, 'id': 'call_lcWOqF5LVUUk4igldM4wRhYM', 'type': 'tool_call'}], usage_metadata={'input_tokens': 162, 'output_tokens': 55, 'total_tokens': 217, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"{'id': 1, 'title': 'bring milk', 'priority': 'high', 'status': 'pending'}\", name='add_task', tool_call_id='call_PA3Ro2oFSfeK4c5QvxDHPQDs'), ToolMessage(content=\"{'id': 2, 'title': 'clean the house', 'priority': 'medium', 'status': 'pending'}\", name='add_task', tool_call_id='call_lcWOqF5LVUUk4igldM4wRhYM'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_k2qrU2eFWHnizJDbv0gErQhB', 'function': {'arguments': '{\"task_id\": 1}', 'name': 'remove_task'}, 'type': 'function'}, {'id': 'call_jsSobx5FHggl1KxqnYJ61QNQ', 'function': {'arguments': '{\"task_id\": 2, \"priority\": \"very high\"}', 'name': 'update_task'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 282, 'total_tokens': 333, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--12088140-aa72-43f9-bd82-354d5a44f1fc-0', tool_calls=[{'name': 'remove_task', 'args': {'task_id': 1}, 'id': 'call_k2qrU2eFWHnizJDbv0gErQhB', 'type': 'tool_call'}, {'name': 'update_task', 'args': {'task_id': 2, 'priority': 'very high'}, 'id': 'call_jsSobx5FHggl1KxqnYJ61QNQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 282, 'output_tokens': 51, 'total_tokens': 333, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"{'id': 1}\", name='remove_task', tool_call_id='call_k2qrU2eFWHnizJDbv0gErQhB'), ToolMessage(content=\"{'id': 2, 'title': None, 'priority': 'very high'}\", name='update_task', tool_call_id='call_jsSobx5FHggl1KxqnYJ61QNQ')]\n",
      "Response from 'llm_with_tools.invoke(messages)' command is content='The task to bring milk with high priority and the task to clean the house with medium priority have been added. Then, I deleted task 1 (bring milk) and updated the priority of task 2 (clean the house) to very high.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 370, 'total_tokens': 421, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'finish_reason': 'stop', 'logprobs': None} id='run--e8c0b114-8353-42ba-8dec-995b49fe49f2-0' usage_metadata={'input_tokens': 370, 'output_tokens': 51, 'total_tokens': 421, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "Now, we have entered into should_continue function. After call_model and before should_contninue, langGraph appends the state['mesage']  based the state['message] + response from lllm_with_tools.invoke(messages)\n",
      "Step2: Run the should_continue function -- END\n",
      "In should_continue, message from state['message] is [HumanMessage(content='add task to bring milk as high priority, then add task to clean the house as medium priority. \\n                                Now, delete task 1 and update priority of task 2 to very high', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_PA3Ro2oFSfeK4c5QvxDHPQDs', 'function': {'arguments': '{\"title\": \"bring milk\", \"priority\": \"high\"}', 'name': 'add_task'}, 'type': 'function'}, {'id': 'call_lcWOqF5LVUUk4igldM4wRhYM', 'function': {'arguments': '{\"title\": \"clean the house\", \"priority\": \"medium\"}', 'name': 'add_task'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 162, 'total_tokens': 217, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ce4f24f9-b563-454e-b7a7-4f04b263f23b-0', tool_calls=[{'name': 'add_task', 'args': {'title': 'bring milk', 'priority': 'high'}, 'id': 'call_PA3Ro2oFSfeK4c5QvxDHPQDs', 'type': 'tool_call'}, {'name': 'add_task', 'args': {'title': 'clean the house', 'priority': 'medium'}, 'id': 'call_lcWOqF5LVUUk4igldM4wRhYM', 'type': 'tool_call'}], usage_metadata={'input_tokens': 162, 'output_tokens': 55, 'total_tokens': 217, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"{'id': 1, 'title': 'bring milk', 'priority': 'high', 'status': 'pending'}\", name='add_task', tool_call_id='call_PA3Ro2oFSfeK4c5QvxDHPQDs'), ToolMessage(content=\"{'id': 2, 'title': 'clean the house', 'priority': 'medium', 'status': 'pending'}\", name='add_task', tool_call_id='call_lcWOqF5LVUUk4igldM4wRhYM'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_k2qrU2eFWHnizJDbv0gErQhB', 'function': {'arguments': '{\"task_id\": 1}', 'name': 'remove_task'}, 'type': 'function'}, {'id': 'call_jsSobx5FHggl1KxqnYJ61QNQ', 'function': {'arguments': '{\"task_id\": 2, \"priority\": \"very high\"}', 'name': 'update_task'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 282, 'total_tokens': 333, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--12088140-aa72-43f9-bd82-354d5a44f1fc-0', tool_calls=[{'name': 'remove_task', 'args': {'task_id': 1}, 'id': 'call_k2qrU2eFWHnizJDbv0gErQhB', 'type': 'tool_call'}, {'name': 'update_task', 'args': {'task_id': 2, 'priority': 'very high'}, 'id': 'call_jsSobx5FHggl1KxqnYJ61QNQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 282, 'output_tokens': 51, 'total_tokens': 333, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"{'id': 1}\", name='remove_task', tool_call_id='call_k2qrU2eFWHnizJDbv0gErQhB'), ToolMessage(content=\"{'id': 2, 'title': None, 'priority': 'very high'}\", name='update_task', tool_call_id='call_jsSobx5FHggl1KxqnYJ61QNQ'), AIMessage(content='The task to bring milk with high priority and the task to clean the house with medium priority have been added. Then, I deleted task 1 (bring milk) and updated the priority of task 2 (clean the house) to very high.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 370, 'total_tokens': 421, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'finish_reason': 'stop', 'logprobs': None}, id='run--e8c0b114-8353-42ba-8dec-995b49fe49f2-0', usage_metadata={'input_tokens': 370, 'output_tokens': 51, 'total_tokens': 421, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "tasks Steps:\n",
      "   1. {'id': 2, 'title': None, 'priority': 'very high', 'status': 'pending'}\n",
      "\n",
      "Final Answer: The task to bring milk with high priority and the task to clean the house with medium priority have been added. Then, I deleted task 1 (bring milk) and updated the priority of task 2 (clean the house) to very high.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myresult = run_calculator_agent(\"\"\"add task to bring milk as high priority, then add task to clean the house as medium priority. \n",
    "                                Now, delete task 1 and update priority of task 2 to very high\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e11e6aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='add task to bring milk as high priority, then add task to clean the house as medium priority. \\n                                Now, delete task 1 and update priority of task 2 to very high', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_PA3Ro2oFSfeK4c5QvxDHPQDs', 'function': {'arguments': '{\"title\": \"bring milk\", \"priority\": \"high\"}', 'name': 'add_task'}, 'type': 'function'}, {'id': 'call_lcWOqF5LVUUk4igldM4wRhYM', 'function': {'arguments': '{\"title\": \"clean the house\", \"priority\": \"medium\"}', 'name': 'add_task'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 162, 'total_tokens': 217, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ce4f24f9-b563-454e-b7a7-4f04b263f23b-0', tool_calls=[{'name': 'add_task', 'args': {'title': 'bring milk', 'priority': 'high'}, 'id': 'call_PA3Ro2oFSfeK4c5QvxDHPQDs', 'type': 'tool_call'}, {'name': 'add_task', 'args': {'title': 'clean the house', 'priority': 'medium'}, 'id': 'call_lcWOqF5LVUUk4igldM4wRhYM', 'type': 'tool_call'}], usage_metadata={'input_tokens': 162, 'output_tokens': 55, 'total_tokens': 217, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content=\"{'id': 1, 'title': 'bring milk', 'priority': 'high', 'status': 'pending'}\", name='add_task', tool_call_id='call_PA3Ro2oFSfeK4c5QvxDHPQDs'),\n",
       "  ToolMessage(content=\"{'id': 2, 'title': 'clean the house', 'priority': 'medium', 'status': 'pending'}\", name='add_task', tool_call_id='call_lcWOqF5LVUUk4igldM4wRhYM'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_k2qrU2eFWHnizJDbv0gErQhB', 'function': {'arguments': '{\"task_id\": 1}', 'name': 'remove_task'}, 'type': 'function'}, {'id': 'call_jsSobx5FHggl1KxqnYJ61QNQ', 'function': {'arguments': '{\"task_id\": 2, \"priority\": \"very high\"}', 'name': 'update_task'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 282, 'total_tokens': 333, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--12088140-aa72-43f9-bd82-354d5a44f1fc-0', tool_calls=[{'name': 'remove_task', 'args': {'task_id': 1}, 'id': 'call_k2qrU2eFWHnizJDbv0gErQhB', 'type': 'tool_call'}, {'name': 'update_task', 'args': {'task_id': 2, 'priority': 'very high'}, 'id': 'call_jsSobx5FHggl1KxqnYJ61QNQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 282, 'output_tokens': 51, 'total_tokens': 333, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content=\"{'id': 1}\", name='remove_task', tool_call_id='call_k2qrU2eFWHnizJDbv0gErQhB'),\n",
       "  ToolMessage(content=\"{'id': 2, 'title': None, 'priority': 'very high'}\", name='update_task', tool_call_id='call_jsSobx5FHggl1KxqnYJ61QNQ'),\n",
       "  AIMessage(content='The task to bring milk with high priority and the task to clean the house with medium priority have been added. Then, I deleted task 1 (bring milk) and updated the priority of task 2 (clean the house) to very high.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 370, 'total_tokens': 421, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'finish_reason': 'stop', 'logprobs': None}, id='run--e8c0b114-8353-42ba-8dec-995b49fe49f2-0', usage_metadata={'input_tokens': 370, 'output_tokens': 51, 'total_tokens': 421, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'tasks': [{'id': 2,\n",
       "   'title': None,\n",
       "   'priority': 'very high',\n",
       "   'status': 'pending'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd79833b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['messages', 'tasks'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myresult.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
